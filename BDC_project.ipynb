{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work With Files\n",
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "# Useful libraries:\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# To Plot:\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Pyspark Lib:\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_BUCKET = 'gs://nyc_comp_bk/'\n",
    "PATH_DATA = '/home/ubuntu/NYC_Taxi/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/ubuntu/NYC_Taxi/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Work_On_Bucket():\n",
    "    \n",
    "    def __init__(self, bucket_name):\n",
    "        # Get access to the bucket:\n",
    "        storage_client = storage.Client()\n",
    "        self.bucket = storage_client.get_bucket(bucket_name)\n",
    "        \n",
    "    def get_file_from_bucket(self, file_name, save_path):\n",
    "        # Download the file:\n",
    "        blob = self.bucket.blob(file_name)\n",
    "        blob.download_to_filename(''.join([save_path, file_name]))\n",
    "            \n",
    "    def upload_file_to_bucket(self, file_name, folder_path):\n",
    "        # Upload the File\n",
    "        object_to_save = self.bucket.blob(file_name)\n",
    "        object_to_save.upload_from_filename(folder_path + file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bucket = Work_On_Bucket('nyc_comp_bk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
      "Downloading new-york-city-taxi-fare-prediction.zip to /home/ubuntu/NYC_Taxi\n",
      " 99%|█████████████████████████████████████▋| 1.55G/1.56G [00:25<00:00, 56.1MB/s]\n",
      "100%|██████████████████████████████████████| 1.56G/1.56G [00:25<00:00, 66.2MB/s]\n",
      "Archive:  new-york-city-taxi-fare-prediction.zip\n",
      "  inflating: /home/ubuntu/NYC_Taxi/data/GCP-Coupons-Instructions.rtf  \n",
      "  inflating: /home/ubuntu/NYC_Taxi/data/sample_submission.csv  \n",
      "  inflating: /home/ubuntu/NYC_Taxi/data/test.csv  \n",
      "  inflating: /home/ubuntu/NYC_Taxi/data/train.csv  \n"
     ]
    }
   ],
   "source": [
    "# Set kaggle:\n",
    "! mkdir ~/.kaggle\n",
    "Bucket.get_file_from_bucket('kaggle.json', '/home/ubuntu/NYC_Taxi/')\n",
    "! cp /home/ubuntu/NYC_Taxi/kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Download The Dataset\n",
    "!kaggle competitions download -c new-york-city-taxi-fare-prediction\n",
    "\n",
    "# Unzip the Files\n",
    "! unzip new-york-city-taxi-fare-prediction.zip -d /home/ubuntu/NYC_Taxi/data/\n",
    "! rm new-york-city-taxi-fare-prediction.zip\n",
    "\n",
    "# Upload databses to bucket:\n",
    "print('Start Uploding!')\n",
    "Bucket.upload_file_to_bucket('train.csv', PATH_DATA)\n",
    "Bucket.upload_file_to_bucket('test.csv', PATH_DATA)\n",
    "print('Succesfully Uploaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Steps (Load + Checks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data:\n",
    "train = spark.read.load(PATH_BUCKET+\"train.csv\", format=\"csv\", inferSchema=\"true\", header=\"true\")\n",
    "test = spark.read.load(PATH_BUCKET+\"test.csv\", format=\"csv\", inferSchema=\"true\", header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset is 55423856 rows by 8 columns\n"
     ]
    }
   ],
   "source": [
    "# Get DB shape:\n",
    "ncol = len(train.columns)\n",
    "nrow = train.count()\n",
    "print(\"The shape of the dataset is {:d} rows by {:d} columns\".format(nrow, ncol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: timestamp (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the schema:\n",
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Variables:\n",
    "X_train = train.select(train.columns[2:])\n",
    "X_test = test.select(train.columns[2:])\n",
    "Y_train = train.select(col(\"fare_amount\"))\n",
    "Y_test = test.select(col(\"fare_amount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+---------------+-----------------+----------------+---------------+\n",
      "|     pickup_datetime|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|passenger_count|\n",
      "+--------------------+----------------+---------------+-----------------+----------------+---------------+\n",
      "|2009-06-15 17:26:...|      -73.844311|      40.721319|        -73.84161|       40.712278|              1|\n",
      "|2010-01-05 16:52:...|      -74.016048|      40.711303|       -73.979268|       40.782004|              1|\n",
      "|2011-08-18 00:35:...|      -73.982738|       40.76127|       -73.991242|       40.750562|              2|\n",
      "|2012-04-21 04:30:...|       -73.98713|      40.733143|       -73.991567|       40.758092|              1|\n",
      "|2010-03-09 07:51:...|      -73.968095|      40.768008|       -73.956655|       40.783762|              1|\n",
      "+--------------------+----------------+---------------+-----------------+----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|fare_amount|\n",
      "+-----------+\n",
      "|        4.5|\n",
      "|       16.9|\n",
      "|        5.7|\n",
      "|        7.7|\n",
      "|        5.3|\n",
      "+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>55423856</td>\n",
       "      <td>55423856</td>\n",
       "      <td>55423856</td>\n",
       "      <td>55423480</td>\n",
       "      <td>55423480</td>\n",
       "      <td>55423856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>None</td>\n",
       "      <td>-72.50968444358728</td>\n",
       "      <td>39.91979178688818</td>\n",
       "      <td>-72.5112097297181</td>\n",
       "      <td>39.92068144482886</td>\n",
       "      <td>1.6853799201556816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>None</td>\n",
       "      <td>12.84888338140265</td>\n",
       "      <td>9.642353041994934</td>\n",
       "      <td>12.78219651783077</td>\n",
       "      <td>9.633345796415126</td>\n",
       "      <td>1.327664357095968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>2009-01-01 00:00:27 UTC</td>\n",
       "      <td>-3442.059565</td>\n",
       "      <td>-3492.263768</td>\n",
       "      <td>-3442.024565</td>\n",
       "      <td>-3547.886698</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>2015-06-30 23:59:54 UTC</td>\n",
       "      <td>3457.625683</td>\n",
       "      <td>3408.789565</td>\n",
       "      <td>3457.62235</td>\n",
       "      <td>3537.132528</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary          pickup_datetime    pickup_longitude    pickup_latitude  \\\n",
       "0   count                 55423856            55423856           55423856   \n",
       "1    mean                     None  -72.50968444358728  39.91979178688818   \n",
       "2  stddev                     None   12.84888338140265  9.642353041994934   \n",
       "3     min  2009-01-01 00:00:27 UTC        -3442.059565       -3492.263768   \n",
       "4     max  2015-06-30 23:59:54 UTC         3457.625683        3408.789565   \n",
       "\n",
       "   dropoff_longitude   dropoff_latitude     passenger_count  \n",
       "0           55423480           55423480            55423856  \n",
       "1  -72.5112097297181  39.92068144482886  1.6853799201556816  \n",
       "2  12.78219651783077  9.633345796415126   1.327664357095968  \n",
       "3       -3442.024565       -3547.886698                   0  \n",
       "4         3457.62235        3537.132528                 208  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show some basic Statistics:\n",
    "stats = X_train.describe()\n",
    "stats.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickup_datetime: 0\n",
      "pickup_longitude: 0\n",
      "pickup_latitude: 0\n",
      "dropoff_longitude: 376\n",
      "dropoff_latitude: 376\n",
      "passenger_count: 0\n"
     ]
    }
   ],
   "source": [
    "# Check Nulls:\n",
    "for c in X_train.columns:\n",
    "    nans = X_train.where(col(c).isNull()).count()\n",
    "    print('{:s}: {:d}'.format(c, nans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Rows with Missing Values:\n",
    "X_train = X_train.na.drop(how='any')\n",
    "Y_train = Y_train.na.drop(how='any')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
