{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a26efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pyspark_dist_explore\n",
    "!pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b12b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work With Files\n",
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "# Useful libraries:\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from functools import reduce\n",
    "\n",
    "# To Plot:\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark_dist_explore import hist\n",
    "\n",
    "# Pyspark Lib:\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "# Preprocess:\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "# Pysparl ML:\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd12025",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_BUCKET = 'gs://nyc_comp_bk/'\n",
    "PATH_DATA = '/home/ubuntu/NYC_Taxi/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cb6c362",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/ubuntu/NYC_Taxi/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20770988",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Work_On_Bucket():\n",
    "    \n",
    "    def __init__(self, bucket_name):\n",
    "        # Get access to the bucket:\n",
    "        storage_client = storage.Client()\n",
    "        self.bucket = storage_client.get_bucket(bucket_name)\n",
    "        \n",
    "    def get_file_from_bucket(self, file_name, save_path):\n",
    "        # Download the file:\n",
    "        blob = self.bucket.blob(file_name)\n",
    "        blob.download_to_filename(''.join([save_path, file_name]))\n",
    "            \n",
    "    def upload_file_to_bucket(self, file_name, folder_path):\n",
    "        # Upload the File\n",
    "        object_to_save = self.bucket.blob(file_name)\n",
    "        object_to_save.upload_from_filename(folder_path + file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e07b4d",
   "metadata": {},
   "source": [
    "### Get the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "142e07dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bucket = Work_On_Bucket('nyc_comp_bk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ae922fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
     ]
    }
   ],
   "source": [
    "# Set kaggle:\n",
    "! mkdir ~/.kaggle\n",
    "Bucket.get_file_from_bucket('kaggle.json', '/home/ubuntu/NYC_Taxi/')\n",
    "! cp /home/ubuntu/NYC_Taxi/kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8960d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading new-york-city-taxi-fare-prediction.zip to /home/ubuntu/NYC_Taxi\n",
      "100%|██████████████████████████████████████▉| 1.56G/1.56G [00:16<00:00, 128MB/s]\n",
      "100%|███████████████████████████████████████| 1.56G/1.56G [00:16<00:00, 104MB/s]\n",
      "Archive:  new-york-city-taxi-fare-prediction.zip\n",
      "  inflating: /home/ubuntu/NYC_Taxi/data/GCP-Coupons-Instructions.rtf  \n",
      "  inflating: /home/ubuntu/NYC_Taxi/data/sample_submission.csv  \n",
      "  inflating: /home/ubuntu/NYC_Taxi/data/test.csv  \n",
      "  inflating: /home/ubuntu/NYC_Taxi/data/train.csv  \n",
      "Start Uploding!\n",
      "Succesfully Uploaded!\n"
     ]
    }
   ],
   "source": [
    "# Download The Dataset\n",
    "!kaggle competitions download -c new-york-city-taxi-fare-prediction\n",
    "\n",
    "# Unzip the Files\n",
    "! unzip new-york-city-taxi-fare-prediction.zip -d /home/ubuntu/NYC_Taxi/data/\n",
    "! rm new-york-city-taxi-fare-prediction.zip\n",
    "\n",
    "# Upload databses to bucket:\n",
    "print('Start Uploding!')\n",
    "Bucket.upload_file_to_bucket('train.csv', PATH_DATA)\n",
    "Bucket.upload_file_to_bucket('test.csv', PATH_DATA)\n",
    "print('Succesfully Uploaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ae495d",
   "metadata": {},
   "source": [
    "### Preliminary Steps (Load + Checks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1134c876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data:\n",
    "train = spark.read.load(PATH_BUCKET+\"train.csv\", format=\"csv\", inferSchema=\"true\", header=\"true\")\n",
    "test = spark.read.load(PATH_BUCKET+\"test.csv\", format=\"csv\", inferSchema=\"true\", header=\"true\")\n",
    "\n",
    "# Load Test (Because pyspark changes the timestamp):\n",
    "Bucket.get_file_from_bucket('test.csv', '')\n",
    "original_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10d57678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset is 55423856 rows by 8 columns\n"
     ]
    }
   ],
   "source": [
    "# Get DB shape:\n",
    "ncol = len(train.columns)\n",
    "nrow = train.count()\n",
    "print(\"The shape of the dataset is {:d} rows by {:d} columns\".format(nrow, ncol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ed53189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: timestamp (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the schema:\n",
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd969782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Key, not needed:\n",
    "train = train.drop('key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64e22027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>55423856</td>\n",
       "      <td>55423856</td>\n",
       "      <td>55423856</td>\n",
       "      <td>55423856</td>\n",
       "      <td>55423480</td>\n",
       "      <td>55423480</td>\n",
       "      <td>55423856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>11.345045601663855</td>\n",
       "      <td>None</td>\n",
       "      <td>-72.50968444358728</td>\n",
       "      <td>39.91979178688818</td>\n",
       "      <td>-72.5112097297181</td>\n",
       "      <td>39.92068144482884</td>\n",
       "      <td>1.6853799201556816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>20.7108321982325</td>\n",
       "      <td>None</td>\n",
       "      <td>12.848883381402654</td>\n",
       "      <td>9.642353041994934</td>\n",
       "      <td>12.782196517830771</td>\n",
       "      <td>9.633345796415126</td>\n",
       "      <td>1.327664357095968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>2009-01-01 00:00:27 UTC</td>\n",
       "      <td>-3442.059565</td>\n",
       "      <td>-3492.263768</td>\n",
       "      <td>-3442.024565</td>\n",
       "      <td>-3547.886698</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>93963.36</td>\n",
       "      <td>2015-06-30 23:59:54 UTC</td>\n",
       "      <td>3457.625683</td>\n",
       "      <td>3408.789565</td>\n",
       "      <td>3457.62235</td>\n",
       "      <td>3537.132528</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary         fare_amount          pickup_datetime    pickup_longitude  \\\n",
       "0   count            55423856                 55423856            55423856   \n",
       "1    mean  11.345045601663855                     None  -72.50968444358728   \n",
       "2  stddev    20.7108321982325                     None  12.848883381402654   \n",
       "3     min              -300.0  2009-01-01 00:00:27 UTC        -3442.059565   \n",
       "4     max            93963.36  2015-06-30 23:59:54 UTC         3457.625683   \n",
       "\n",
       "     pickup_latitude   dropoff_longitude   dropoff_latitude  \\\n",
       "0           55423856            55423480           55423480   \n",
       "1  39.91979178688818   -72.5112097297181  39.92068144482884   \n",
       "2  9.642353041994934  12.782196517830771  9.633345796415126   \n",
       "3       -3492.263768        -3442.024565       -3547.886698   \n",
       "4        3408.789565          3457.62235        3537.132528   \n",
       "\n",
       "      passenger_count  \n",
       "0            55423856  \n",
       "1  1.6853799201556816  \n",
       "2   1.327664357095968  \n",
       "3                   0  \n",
       "4                 208  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show some basic Statistics:\n",
    "stats = train.select(train.columns[1:]).describe()\n",
    "stats.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3993b2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickup_datetime: 0\n",
      "pickup_longitude: 0\n",
      "pickup_latitude: 0\n",
      "dropoff_longitude: 376\n",
      "dropoff_latitude: 376\n",
      "passenger_count: 0\n"
     ]
    }
   ],
   "source": [
    "# Check Nulls:\n",
    "for c in train.columns[2:]:\n",
    "    nans = train.where(col(c).isNull()).count()\n",
    "    print('{:s}: {:d}'.format(c, nans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12cfd3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Rows with Missing Values:\n",
    "train = train.na.drop(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40557405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Duplicates are: 1650\n"
     ]
    }
   ],
   "source": [
    "# Check Duplicates:\n",
    "print('The Duplicates are: {:d}'.format(train.count()-train.distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dab813bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Duplicates:\n",
    "train = train.distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1232b4b5",
   "metadata": {},
   "source": [
    "### Create My Base Line:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c8250",
   "metadata": {},
   "source": [
    "As Base Line I am going to use a Multiple Linear Regression that takes as input all the scaled (mean=0, sd=1) numerical variables.\n",
    "As result I get an RMSE = 9.40719 on the Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7ca7ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL = ['pickup_longitude',\n",
    "            'pickup_latitude',\n",
    "            'dropoff_longitude',\n",
    "            'dropoff_latitude',\n",
    "            'passenger_count']\n",
    "TARGET = 'fare_amount'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42c9e18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature Vector:\n",
    "assembler = VectorAssembler(inputCols=NUMERICAL, outputCol=\"features\")\n",
    "train_df = assembler.transform(train.filter('fare_amount > 2.50 AND fare_amount < 1000'))\n",
    "train_df = train_df.select('features', TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2264528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Data:\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"ScaledFeatures\")\n",
    "scalerModel = scaler.fit(train_df)\n",
    "train_df = scalerModel.transform(train_df)\n",
    "train_df = train_df.select('ScaledFeatures', TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7665ecc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Training Set *****\n",
      "RMSE: 9.792\n",
      "MAE: 6.030\n",
      "R2: 0.000\n",
      "***** Training Set *****\n"
     ]
    }
   ],
   "source": [
    "# Run the Linear Regression:\n",
    "lr = LinearRegression(featuresCol=\"ScaledFeatures\", labelCol=TARGET, maxIter=10)\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "# Print Stats:\n",
    "training_result = lr_model.summary\n",
    "print(\"***** Training Set *****\")\n",
    "print(\"RMSE: {:.3f}\".format(training_result.rootMeanSquaredError))\n",
    "print(\"MAE: {:.3f}\".format(training_result.meanAbsoluteError))\n",
    "print(\"R2: {:.3f}\".format(training_result.r2))\n",
    "print(\"***** Training Set *****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e13f7054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName        date                 description       status    publicScore  privateScore  \n",
      "--------------  -------------------  ----------------  --------  -----------  ------------  \n",
      "submission.csv  2021-06-26 11:42:04  First Submission  complete  9.40719      9.40719       \n",
      "submission.csv  2021-06-23 15:15:57  First Submission  complete  9.40712      9.40712       \n",
      "submission.csv  2021-06-23 15:10:56  First Submission  complete  9.40712      9.40712       \n",
      "submission.csv  2021-06-23 14:58:58  None              error     None         None          \n",
      "submission.csv  2021-06-23 14:58:06  First Submission  error     None         None          \n",
      "submission.csv  2021-06-23 14:55:46  None              error     None         None          \n",
      "submission.csv  2021-06-23 14:54:33  First Submission  error     None         None          \n",
      "submission.csv  2021-06-23 14:52:36  None              error     None         None          \n",
      "submission.csv  2021-06-23 14:51:55  First Submission  error     None         None          \n",
      "submission.csv  2021-06-23 14:51:27  First Submission  error     None         None          \n",
      "submission.csv  2021-06-23 14:49:09  None              error     None         None          \n",
      "submission.csv  2021-06-23 14:47:35  First Submission  error     None         None          \n"
     ]
    }
   ],
   "source": [
    "# Prepare the test:\n",
    "test_df = assembler.transform(test.select(NUMERICAL))\n",
    "test_df = test_df.select('features')\n",
    "test_df = scalerModel.transform(test_df)\n",
    "\n",
    "# Make Predictions:\n",
    "predictions = lr_model.transform(test_df).select('prediction').withColumnRenamed('prediction','fare_amount').toPandas()\n",
    "\n",
    "# Prepare the Submission:\n",
    "submission = pd.concat([original_test['key'], predictions['fare_amount']], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# Submit:\n",
    "!kaggle competitions submit -c new-york-city-taxi-fare-prediction -f submission.csv -m \"First Submission\"\n",
    "!kaggle competitions submissions -c new-york-city-taxi-fare-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0965671",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf478d9",
   "metadata": {},
   "source": [
    "#### 1) Latitude and Longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f40cc5",
   "metadata": {},
   "source": [
    "From the study of the quantiles it is clear that there are many outlayers, because the NYC coordinates are (lat=40.730610 lon=-73.935242). Even working with quantiles, removing anything out of the I and III quartile things don't change so much. Therefore, I opt for anothe option, I draw a triangle around the area of interest, a triangle because NY City is on an icleand which reminds a triangle, but the area is bigger than the iceland, to take into acocunt possible trips from the countriside. Everything outside the triangle will be dropped. In order to have a more permissive approach, it is possible to draw a rectangle and include more points: It seems that there are many taxis that go and come from/to the states placed at the North of NYC. To decide whether a point is in the triangle I walk clockwise or counterclockwise around the triangle and project the point onto the segment I am crossing by using the dot product. Finally, I check that the vector created is on the same side for each of the triangle's segments.\n",
    "There is another issues linked with the coordinates, there are some points (both for pick up and drop off) which are located in the ocean, There are different libraries that can help in remving them, by masking the map, but it takes too much computational resources. Another possibility is to define a more complex shape (instead of a triangle) that defines bounderies more accurately, but this option is too expensive in terms of computation, too (no easy way to compute if a point is in a complex geometric figure). Not having any alternatives I keep them hopping that they won't affect my model too much. \n",
    "For what concerns how pick up and drop off locations are distributed in the map, as I expected they are mostly concentrated in Manhattan. Howevere, there are two areas outside it, which seems to have an important tarffic of Taxi: one is the JFK Airport and the other one is a point in Hamilton Town in New Jersy. In addition, it is possible to check that drop off locations are more spread all along NYC than pickup ones that are more concentrated in Manhattan. For what concerns the avarage fare amount for a trip, it seems to increase the further the trip ends outised Mantthan and if a trip start or stop from/in the JFK airport, but here also the time variables play a role (let's see in the next part). Finally, it seems that some trips are repeted more frequently, the mode is 1, but for some observations the count can arrive up to 36 (and potentially more, for the full dataset). This suggest me that there are some people tha use it regularly, they may get a discount for that reason, a kind of subscription. Given that they are very few, for the moment I am not going to create a variable ad hoc (taking also into account that the data are spread over 6 years, 36 times is not such a significant amount).\n",
    "\n",
    "\n",
    "The it is possible to compute new features that can be useful both for the model and to remove more outlayers, namely the Absolute Distance, the Haversinee Distance and the Minkowski Distance (that for p=1 is the Manhattan and for p=2 is the Euclidean distance). All the distances are expressed in kilometers. To obtain some of them I need to know to how much km corresponds the variation of 1 degree for each coordinates and it turns put that for Latitude it is 111 Km and for Longitude is 85 Km. Checking the statistics of th emetrics it is clear that there are many outlayers. To drop them I am going to use a kind of voting, for each observation I get the mean of manhattan, euclidean and haversine distances metrics and remove the observation if its distance mean is less than 0.5 (namel less than 500m trip).\n",
    "\n",
    "Another feature that can improve my model is the direction (in degree) of the trip. Because the computed distancem is only an approximation and o the angle can improve this approximation. To comput the distance I use the Bearing Algorithm and I multiply the result by -1 because of the negative longitude.\n",
    "\n",
    "Exploiting the function to compute the haversian distance (which is the more realistic) I compute the distanes from the airports, both for pick up and drop off and I create a column that says whether the pick up or dorp off happened near by the airport. It is possible that there the costs are higher or maybe fixed. It is possible to check using a groupby that the average price is far away higher than the one for a standard trip. Furthermore, for rhe most of them the standard deviation shows that maybe the prices are not fixed or anyway that the prices can change up to +/-30$ for the most volatile airport (EWR).\n",
    "\n",
    "Then I suppose that a there must be a relationship between fear amount and length of the trip (it maybe also connected with duration). Hence, I create a variable tha distinguish among trips under the mean and over the mean. It seems that my hypothesis is confirmed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1076e11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3442.059565,  2123.82246 ,  3457.625683],\n",
       "       [-3492.263768,   444.133332,  3408.789565],\n",
       "       [-3442.024565,   -73.980088,  3457.62235 ],\n",
       "       [-3547.886698,  2599.28739 ,  3537.132528]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check I, II and III Quantiles:\n",
    "np.array([train.approxQuantile('pickup_longitude', [0.25, 0.50, 0.75], 0.25),\n",
    "          train.approxQuantile('pickup_latitude', [0.25, 0.50, 0.75], 0.25),\n",
    "          train.approxQuantile('dropoff_longitude', [0.25, 0.50, 0.75], 0.25),\n",
    "          train.approxQuantile('dropoff_latitude', [0.25, 0.50, 0.75], 0.25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d1076fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write function to check if a point is a triangle:\n",
    "\n",
    "def point_in_triangle(lat, long):\n",
    "    \"\"\"\n",
    "    phuclv (https://stackoverflow.com/questions/2049582/how-to-determine-if-a-point-is-in-a-2d-triangle)\n",
    "    To decide whether a point is in the triangle walk clockwise or counterclockwise around the triangle and \n",
    "    project the point onto the segment crossing by using the dot product. \n",
    "    Finally, check that the vector created is on the same side for each of the triangle's segments.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lat : float\n",
    "        The latitude coordinate of a point\n",
    "    long :float\n",
    "        The longitude oordinate of a point\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        whether all signs of the sides are positive/negative\n",
    "    \"\"\"\n",
    "    # Unpack arguments\n",
    "    x = lat\n",
    "    y = long\n",
    "    ax, ay = (39.74274655286439, -75.26399018397262)\n",
    "    bx, by = (41.58840050439113, -75.18708588709761)\n",
    "    cx, cy = (41.07279488244855, -71.76484467616011)\n",
    "    # Segment A to B\n",
    "    side_1 = (x - bx) * (ay - by) - (ax - bx) * (y - by)\n",
    "    # Segment B to C\n",
    "    side_2 = (x - cx) * (by - cy) - (bx - cx) * (y - cy)\n",
    "    # Segment C to A\n",
    "    side_3 = (x - ax) * (cy - ay) - (cx - ax) * (y - ay)\n",
    "    # All the signs must be positive or all negative\n",
    "    return (side_1 < 0.0) == (side_2 < 0.0) == (side_3 < 0.0)\n",
    "\n",
    "def is_in_area(lat1, lon1, lat2, lon2):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Check whether both pick up and drop off points of an observation\n",
    "    are in the triangle.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lat1 : float\n",
    "        The latitude coordinate of a pick up point\n",
    "    long1 :float\n",
    "        The longitude oordinate of a pick up point\n",
    "        \n",
    "    lat2 : float\n",
    "        The latitude coordinate of a drop off point\n",
    "    long2 :float\n",
    "        The longitude oordinate of a drop off point\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        whether both the points are in the hotspot\n",
    "    \"\"\"\n",
    "    \n",
    "    pick = point_in_triangle(lat1, lon1)\n",
    "    drop = point_in_triangle(lat2, lon2)\n",
    "    \n",
    "    return all([pick, drop])\n",
    "\n",
    "is_in_area_udf = F.udf(is_in_area, BooleanType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a17f94e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any point outside the given area:\n",
    "train = train.withColumn('keep', is_in_area_udf( col('pickup_latitude'), col('pickup_longitude'), col('dropoff_latitude'), col('dropoff_longitude') ) )\n",
    "train = train.filter(\"keep == True\")\n",
    "train = train.drop('keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66c8fe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------------------+-------------------+--------------------+\n",
      "|summary|     pickup_latitude|   pickup_longitude|   dropoff_latitude|   dropoff_longitude|\n",
      "+-------+--------------------+-------------------+-------------------+--------------------+\n",
      "|  count|            54235168|           54235168|           54235168|            54235168|\n",
      "|   mean|   40.75084046363401| -73.97546359704323|  40.75123945667267|  -73.97456012998938|\n",
      "| stddev|0.027549044484391723|0.03574727580738844|0.03143901853685563|0.035618188092662054|\n",
      "|    min|           39.804188| -75.25401306152344|           39.80016|  -75.25403594970703|\n",
      "|    max|           41.519495|           -72.0619|          41.567147|           -71.97642|\n",
      "+-------+--------------------+-------------------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.select(col('pickup_latitude'), col('pickup_longitude'), col('dropoff_latitude'), col('dropoff_longitude')).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44021553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Functions needed to Create Coordinates Features\n",
    "\n",
    "class Coordinates_Transform():\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.df = df\n",
    "        self.haversine_udf = F.udf(Coordinates_Transform.haversine_stat, DoubleType())\n",
    "        self.direction_udf = F.udf(Coordinates_Transform.calculate_dir, DoubleType())\n",
    "        self.airports_udf = F.udf(Coordinates_Transform.identify_airports, StringType())\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def haversine_stat(pick_lat, drop_lat, pick_long, drop_long):\n",
    "\n",
    "        longit_a, latit_a, longit_b, latit_b = map(math.radians, [pick_long,  pick_lat, drop_long, drop_lat])\n",
    "        dist_longit = longit_b - longit_a\n",
    "        dist_latit = latit_b - latit_a\n",
    "        # Calculate area\n",
    "        area = math.sin(dist_latit/2)**2 + math.cos(latit_a) * math.cos(latit_b) * math.sin(dist_longit/2)**2\n",
    "        # Calculate the central angle\n",
    "        central_angle = 2 * math.asin(math.sqrt(area))\n",
    "        RADIUS = 6371\n",
    "        # Calculate Distance\n",
    "        distance = central_angle * RADIUS\n",
    "        return round(distance, 3)\n",
    "\n",
    "    def add_dist_metrics(self):\n",
    "       \n",
    "        # Absolute Lat e Long Distance:\n",
    "        self.df = self.df.withColumn( 'abs_dist_longitude', F.round( F.abs( col('pickup_longitude') - col('dropoff_longitude') ) * 85, 3 ) )\n",
    "        self.df = self.df.withColumn( 'abs_dist_latitude', F.round( F.abs( col('pickup_latitude') - col('dropoff_latitude') ) * 111 , 3 ) )\n",
    "\n",
    "        # Manhattan Distance:\n",
    "        self.df = self.df.withColumn( 'manhattan_dist', F.round( col('abs_dist_longitude') + col('abs_dist_latitude'), 3 ) )\n",
    "\n",
    "        # Euclidean Distance:\n",
    "        self.df = self.df.withColumn( 'euclidean_dist',  F.round( F.sqrt( col('abs_dist_longitude')**2 + col('abs_dist_latitude')**2 ), 3 ) )\n",
    "\n",
    "        # Haversine Distance:\n",
    "        self.df = self.df.withColumn( 'haversine_dist', \n",
    "                                     self.haversine_udf( col('pickup_latitude'), col('dropoff_latitude'), col('pickup_longitude'), col('dropoff_longitude') ) ) \n",
    "\n",
    "        return self.df\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_dir(lat1, lon1, lat2, lon2):\n",
    "\n",
    "        '''\n",
    "        https://www.movable-type.co.uk/scripts/latlong.html\n",
    "        It is measured in 0 - 360 degrees\n",
    "        '''\n",
    "\n",
    "        dlon = lon2 - lon1\n",
    "        y = math.sin(dlon) * math.cos(lat2)\n",
    "        x = math.cos(lat1) * math.sin(lat2) - math.sin(lat1) * math.cos(lat2) * math.cos(dlon)\n",
    "        theta = math.atan2(y, x)*180/math.pi\n",
    "\n",
    "        return (-theta + 360) % 360\n",
    "\n",
    "\n",
    "\n",
    "    def direction(self):\n",
    "        self.df = self.df.withColumn('direction', self.direction_udf( col('pickup_latitude'), col('pickup_longitude'), col('dropoff_latitude'), col('dropoff_longitude') ))\n",
    "        return self.df\n",
    "\n",
    "    def third_dim_remap(self):\n",
    "        '''\n",
    "        The credit for the next features goes to Jan van der Vegt @datascience.stackexchange.com\n",
    "        https://datascience.stackexchange.com/users/14904/jan-van-der-vegt\n",
    "        '''\n",
    "        # Compute coordinates for pickup:\n",
    "        self.df = self.df.withColumn('pickup_x', F.cos('pickup_latitude') * F.cos('pickup_longitude'))\n",
    "        self.df = self.df.withColumn('pickup_y', F.cos('pickup_latitude') * F.sin('pickup_longitude'))\n",
    "        self.df = self.df.withColumn('pickup_z', F.sin('pickup_latitude'))\n",
    "\n",
    "        # Compute coordinates for dropoff\n",
    "        self.df = self.df.withColumn('dropoff_x', F.cos('dropoff_latitude') * F.cos('dropoff_longitude'))\n",
    "        self.df = self.df.withColumn('dropoff_y', F.cos('dropoff_latitude') * F.sin('dropoff_longitude'))\n",
    "        self.df = self.df.withColumn('dropoff_z', F.sin('dropoff_latitude'))\n",
    "\n",
    "        return self.df\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def identify_airports(pick_lat, drop_lat, pick_long, drop_long):\n",
    "\n",
    "        # Set the coordinates of airports:\n",
    "        JFK_LAT = 40.641766\n",
    "        JFK_LON = -73.780968\n",
    "\n",
    "        LGR_LAT = 40.773013\n",
    "        LGR_LON = -73.870229\n",
    "\n",
    "        EWR_LAT = 40.689531\n",
    "        EWR_LON = -74.174462\n",
    "\n",
    "        # Compute distances:\n",
    "        pick_up_jfk = Coordinates_Transform.haversine_stat(JFK_LAT, pick_lat, JFK_LON, pick_long)\n",
    "        drop_off_jfk = Coordinates_Transform.haversine_stat(drop_lat, JFK_LAT, drop_long, JFK_LON)\n",
    "\n",
    "        pick_up_lgr = Coordinates_Transform.haversine_stat(LGR_LAT, pick_lat, LGR_LON, pick_long)\n",
    "        drop_off_lgr = Coordinates_Transform.haversine_stat(drop_lat, LGR_LAT, drop_long, LGR_LON)\n",
    "\n",
    "        pick_up_ewr = Coordinates_Transform.haversine_stat(EWR_LAT, pick_lat, EWR_LON, pick_long)\n",
    "        drop_off_ewr = Coordinates_Transform.haversine_stat(drop_lat, EWR_LAT, drop_long, EWR_LON)\n",
    "\n",
    "        print(pick_up_jfk, drop_off_jfk)\n",
    "        # Assign a value:\n",
    "        if pick_up_jfk < 1:\n",
    "            return 'PICK_JFK'\n",
    "        elif drop_off_jfk < 1:\n",
    "            return 'DROP_JFK'\n",
    "        if pick_up_lgr < 1:\n",
    "            return 'PICK_LGR'\n",
    "        elif drop_off_lgr < 1:\n",
    "            return 'DROP_LGR'\n",
    "        if pick_up_ewr < 1:\n",
    "            return 'PICK_EWR'\n",
    "        elif drop_off_ewr < 1:\n",
    "            return 'DROP_EWR'\n",
    "        else:\n",
    "            return 'NO_AIRPORT'\n",
    "\n",
    "    def airports(self):\n",
    "\n",
    "        self.df = self.df.withColumn('airport', \n",
    "                                     self.airports_udf( col('pickup_latitude'), col('dropoff_latitude'), col('pickup_longitude'), col('dropoff_longitude') ))\n",
    "        return self.df\n",
    "\n",
    "    def long_short_trip(self):\n",
    "\n",
    "        mean_len = self.df.select('haversine_dist').agg(F.mean(col('haversine_dist'))).first()[0]\n",
    "        self.df = self.df.withColumn( 'long_short', F.when(col('haversine_dist') <= mean_len, 'short') \\\n",
    "                                     .otherwise('long') )\n",
    "        return self.df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3bf865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Distance metrics:\n",
    "coordTransform = Coordinates_Transform(train)\n",
    "train = coordTransform.add_dist_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a7e1e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>abs_dist_longitude</th>\n",
       "      <th>abs_dist_latitude</th>\n",
       "      <th>manhattan_dist</th>\n",
       "      <th>euclidean_dist</th>\n",
       "      <th>haversine_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>54235168</td>\n",
       "      <td>54235168</td>\n",
       "      <td>54235168</td>\n",
       "      <td>54235168</td>\n",
       "      <td>54235168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>1.9286066518499425</td>\n",
       "      <td>2.357046155476089</td>\n",
       "      <td>4.28565280732606</td>\n",
       "      <td>3.3246101278786595</td>\n",
       "      <td>3.315646530605393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>2.887787858818069</td>\n",
       "      <td>2.5609968462258927</td>\n",
       "      <td>4.783709562936858</td>\n",
       "      <td>3.6221773285676875</td>\n",
       "      <td>3.607593005204814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>158.809</td>\n",
       "      <td>128.346</td>\n",
       "      <td>210.365</td>\n",
       "      <td>163.92</td>\n",
       "      <td>162.283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary  abs_dist_longitude   abs_dist_latitude     manhattan_dist  \\\n",
       "0   count            54235168            54235168           54235168   \n",
       "1    mean  1.9286066518499425   2.357046155476089   4.28565280732606   \n",
       "2  stddev   2.887787858818069  2.5609968462258927  4.783709562936858   \n",
       "3     min                 0.0                 0.0                0.0   \n",
       "4     max             158.809             128.346            210.365   \n",
       "\n",
       "       euclidean_dist     haversine_dist  \n",
       "0            54235168           54235168  \n",
       "1  3.3246101278786595  3.315646530605393  \n",
       "2  3.6221773285676875  3.607593005204814  \n",
       "3                 0.0                0.0  \n",
       "4              163.92            162.283  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's Check df:\n",
    "train.select('abs_dist_longitude', 'abs_dist_latitude', 'manhattan_dist', 'euclidean_dist', 'haversine_dist').describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d238cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove outlayers:\n",
    "DIST_METRICS = ['manhattan_dist', 'euclidean_dist', 'haversine_dist']\n",
    "n = len(DIST_METRICS)\n",
    "row_mean  = (sum(col(x) for x in DIST_METRICS) / n).alias(\"mean_dist\")\n",
    "train = train.where( (row_mean >= 0.5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb555879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>abs_dist_longitude</th>\n",
       "      <th>abs_dist_latitude</th>\n",
       "      <th>manhattan_dist</th>\n",
       "      <th>euclidean_dist</th>\n",
       "      <th>haversine_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>52277799</td>\n",
       "      <td>52277799</td>\n",
       "      <td>52277799</td>\n",
       "      <td>52277799</td>\n",
       "      <td>52277799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>1.9966080829072308</td>\n",
       "      <td>2.4408030829874807</td>\n",
       "      <td>4.437411165894727</td>\n",
       "      <td>3.4421882540617297</td>\n",
       "      <td>3.4329118362653372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>2.919377212362032</td>\n",
       "      <td>2.5708288215629684</td>\n",
       "      <td>4.806322907125751</td>\n",
       "      <td>3.636923794344817</td>\n",
       "      <td>3.6221358994083372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>158.809</td>\n",
       "      <td>128.346</td>\n",
       "      <td>210.365</td>\n",
       "      <td>163.92</td>\n",
       "      <td>162.283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary  abs_dist_longitude   abs_dist_latitude     manhattan_dist  \\\n",
       "0   count            52277799            52277799           52277799   \n",
       "1    mean  1.9966080829072308  2.4408030829874807  4.437411165894727   \n",
       "2  stddev   2.919377212362032  2.5708288215629684  4.806322907125751   \n",
       "3     min                 0.0                 0.0                0.5   \n",
       "4     max             158.809             128.346            210.365   \n",
       "\n",
       "       euclidean_dist      haversine_dist  \n",
       "0            52277799            52277799  \n",
       "1  3.4421882540617297  3.4329118362653372  \n",
       "2   3.636923794344817  3.6221358994083372  \n",
       "3                0.44               0.438  \n",
       "4              163.92             162.283  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select('abs_dist_longitude', 'abs_dist_latitude', 'manhattan_dist', 'euclidean_dist', 'haversine_dist').describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d7b95c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Directions:\n",
    "train = coordTransform.direction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7cd4568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add third dimension:\n",
    "train = coordTransform.third_dim_remap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22ecb77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's Add when starting point or arrival is at the airport:\n",
    "train = coordTransform.airports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dbda794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------------+------------------+\n",
      "|   airport|  avg(fare_amount)|stddev_samp(fare_amount)|count(fare_amount)|\n",
      "+----------+------------------+------------------------+------------------+\n",
      "|NO_AIRPORT| 9.883849381264305|       20.12932370022055|          51425249|\n",
      "|  PICK_LGR|30.539708546336954|       11.22933687200242|           1023456|\n",
      "|  DROP_LGR|   31.290757161067|       7.472403972288996|            618204|\n",
      "|  PICK_JFK| 44.04999031117295|      16.279093865880675|            778216|\n",
      "|  DROP_JFK| 50.37918619737053|       8.240775868954858|            321417|\n",
      "|  PICK_EWR| 65.20260009310988|       34.11488374875951|              4296|\n",
      "|  DROP_EWR|  70.8729424840665|      14.005440984793118|             64330|\n",
      "+----------+------------------+------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check avg price for the airports:\n",
    "train.select('airport','fare_amount').groupBy('airport').agg(F.mean('fare_amount'), F.stddev('fare_amount'), F.count('fare_amount')).sort('avg(fare_amount)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d649d213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a binning for the length, based on the haversine distance:\n",
    "train = coordTransform.long_short_trip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b38c1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+------------------------+------------------+\n",
      "|long_short| avg(fare_amount)|stddev_samp(fare_amount)|count(fare_amount)|\n",
      "+----------+-----------------+------------------------+------------------+\n",
      "|      long|19.82420825373721|      22.274972965933255|          16769255|\n",
      "|     short| 7.52029804345085|      18.959355627956782|          37465913|\n",
      "+----------+-----------------+------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check avg price for binned trip length:\n",
    "train.select('long_short' ,'fare_amount').groupBy('long_short').agg(F.mean('fare_amount'), F.stddev('fare_amount'), F.count('fare_amount')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a117719b",
   "metadata": {},
   "source": [
    "#### 2) Time Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "896030ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time_Transform():\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df.withColumn('pickup_datetime', F.substring(col('pickup_datetime'), 1, 19))\\\n",
    "        .withColumn('pickup_datetime', F.to_timestamp(col('pickup_datetime')))\n",
    "        \n",
    "\n",
    "    def get_date(self, remove_original=False):\n",
    "\n",
    "        self.df = self.df.withColumn('pickup_datetime', F.to_timestamp(col('pickup_datetime'))) \\\n",
    "        .withColumn('year', F.year(col('pickup_datetime'))) \\\n",
    "        .withColumn('month', F.month(col('pickup_datetime'))) \\\n",
    "        .withColumn('week_of_year', F.weekofyear(col('pickup_datetime'))) \\\n",
    "        .withColumn('quarter', F.quarter(col('pickup_datetime')))\\\n",
    "        .withColumn('day_of_month', F.dayofmonth(col('pickup_datetime'))) \\\n",
    "        .withColumn('day_of_week', F.dayofweek(col('pickup_datetime'))) \\\n",
    "        .withColumn('day_of_year', F.dayofyear(col('pickup_datetime'))) \\\n",
    "        .withColumn('hour', F.hour(col('pickup_datetime'))) \\\n",
    "        .withColumn('minute', F.minute(col('pickup_datetime'))) \\\n",
    "        .withColumn('second', F.second(col('pickup_datetime')))\n",
    "\n",
    "        if remove_original:\n",
    "            self.df = self.df.drop('pickup_datetime')\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    def is_weekend(self):\n",
    "\n",
    "        self.df = self.df.withColumn('is_week_end', F.when( (col('day_of_week')==6) | (col('day_of_week')==7), 'True' )\\\n",
    "                                    .otherwise('False'))\n",
    "        return self.df\n",
    "\n",
    "\n",
    "    def divide_day(self):\n",
    "\n",
    "        self.df = self.df.withColumn('part_of_day', F.when(col('hour')>=20, 'overnight')\\\n",
    "                                     .when((col('hour')>=0) & (col('hour')<=6), 'overnight')\\\n",
    "                                     .when((col('hour')>6) & (col('hour')<=12), 'morning')\\\n",
    "                                     .when((col('hour')>12) & (col('hour')<16), 'afternoon')\\\n",
    "                                     .when((col('hour')>=16) & (col('hour')<20) & (col('is_week_end')=='False'), 'rush_hour')\\\n",
    "                                     .when((col('hour')>=16) & (col('hour')<20) & (col('is_week_end')=='True'), 'evening'))\n",
    "\n",
    "        return self.df\n",
    "\n",
    "\n",
    "    def add_fractions(self, remove_original=False):\n",
    "\n",
    "        self.df = self.df.withColumn('frac_of_day', ( col('hour') + col('minute')/60 + col('second')/3600 )/23 )\\\n",
    "        .withColumn('frac_of_week',  (col('day_of_week') + col('frac_of_day') )/7) \\\n",
    "        .withColumn('frac_of_month', ( col('day_of_month') + col('frac_of_day') ) / ( F.dayofmonth(F.last_day( col('pickup_datetime') ))+1 ) )\\\n",
    "        .withColumn('frac_of_year', ( col('day_of_year') + col('frac_of_day') )/(365 + 1) )     \n",
    "\n",
    "        if remove_original:\n",
    "            self.df = self.df.drop('pickup_datetime')\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    def cyclical_encoding(self, remove_cat=False):\n",
    "        '''\n",
    "        https://towardsdatascience.com/cyclical-features-encoding-its-about-time-ce23581845ca\n",
    "        https://www.kaggle.com/avanwyk/encoding-cyclical-features-for-deep-learning\n",
    "        A common method for encoding cyclical data is to transform the data into two dimensions using a sine and consine transformation.\n",
    "        We can do that using the following transformations:\n",
    "\n",
    "        xsin=sin(2∗π∗x/max(x)) \n",
    "        xcos=cos(2∗π∗x/max(x))\n",
    "        '''\n",
    "\n",
    "        self.df = self.df.withColumn('month_sin', F.sin(col('month') * 2*math.pi / 12))\\\n",
    "        .withColumn('month_cos', F.cos(col('month') * 2*math.pi / 12))\\\n",
    "        .withColumn('week_of_year_sin', F.sin(col('week_of_year') * 2*math.pi / 52))\\\n",
    "        .withColumn('week_of_year_cos', F.cos(col('week_of_year') * 2*math.pi / 52))\\\n",
    "        .withColumn('quarter_sin', F.sin(col('quarter') * 2*math.pi / 4))\\\n",
    "        .withColumn('quarter_cos', F.cos(col('quarter') * 2*math.pi / 4))\\\n",
    "        .withColumn('day_of_month_sin', F.sin(col('day_of_month') * 2*math.pi / 31))\\\n",
    "        .withColumn('day_of_month_cos', F.cos(col('day_of_month') * 2*math.pi / 31))\\\n",
    "        .withColumn('day_of_week_sin', F.sin(col('day_of_week') * 2*math.pi / 7))\\\n",
    "        .withColumn('day_of_week_cos', F.cos(col('day_of_week') * 2*math.pi / 7))\\\n",
    "        .withColumn('day_of_yearh_sin', F.sin(col('day_of_year') * 2*math.pi / 366))\\\n",
    "        .withColumn('day_of_year_cos', F.cos(col('day_of_year' ) * 2*math.pi / 366))\\\n",
    "        .withColumn('hour_sin', F.sin(col('hour') * 2*math.pi / 23))\\\n",
    "        .withColumn('hour_cos', F.cos(col('hour') * 2*math.pi / 23))\\\n",
    "        .withColumn('minute_sin', F.sin(col('minute') * 2*math.pi / 60))\\\n",
    "        .withColumn('minute_cos', F.cos(col('minute') * 2*math.pi / 60))\n",
    "\n",
    "        if remove_cat:\n",
    "            self.df = self.df.drop('month', 'week_of_year', 'quarter', 'day_of_month', 'day_of_week', 'day_of_year', 'hour')\n",
    "            return self.df\n",
    "        else:\n",
    "            return self.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12d115ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get daates basic info:\n",
    "timeTransform = Time_Transform(train)\n",
    "train = timeTransform.get_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2db14d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+-----+------------+-------+------------+-----------+-----------+----+------+------+\n",
      "|    pickup_datetime|year|month|week_of_year|quarter|day_of_month|day_of_week|day_of_year|hour|minute|second|\n",
      "+-------------------+----+-----+------------+-------+------------+-----------+-----------+----+------+------+\n",
      "|2013-02-25 12:53:52|2013|    2|           9|      1|          25|          2|         56|  12|    53|    52|\n",
      "|2013-03-10 12:22:39|2013|    3|          10|      1|          10|          1|         69|  12|    22|    39|\n",
      "|2012-05-04 13:33:00|2012|    5|          18|      2|           4|          6|        125|  13|    33|     0|\n",
      "|2010-08-12 14:27:00|2010|    8|          32|      3|          12|          5|        224|  14|    27|     0|\n",
      "|2010-05-21 18:57:00|2010|    5|          20|      2|          21|          6|        141|  18|    57|     0|\n",
      "+-------------------+----+-----+------------+-------+------------+-----------+-----------+----+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.select('pickup_datetime','year','month', 'week_of_year', 'quarter','day_of_month', 'day_of_week','day_of_year','hour','minute','second').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "622b05e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if it is weekend:\n",
    "train = timeTransform.is_weekend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71efe33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|is_week_end|  avg(fare_amount)|\n",
      "+-----------+------------------+\n",
      "|      False|11.385143825938746|\n",
      "|       True|11.187080945739638|\n",
      "+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.select('is_week_end', 'fare_amount').groupby('is_week_end').agg(F.mean('fare_amount')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66ab2e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check part of the day:\n",
    "train = timeTransform.divide_day()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d00323a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|part_of_day|  avg(fare_amount)|\n",
      "+-----------+------------------+\n",
      "|  afternoon|11.768674577986591|\n",
      "|  overnight|11.508201533693835|\n",
      "|  rush_hour|11.170062041233122|\n",
      "|    morning|10.992560077359562|\n",
      "|    evening|10.994244561142468|\n",
      "+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.select('part_of_day', 'fare_amount').groupby('part_of_day').agg(F.mean('fare_amount')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdda2756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Time to be used better in the models:\n",
    "train = timeTransform.add_fractions(remove_original=False)\n",
    "train = timeTransform.cyclical_encoding(remove_cat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855af33",
   "metadata": {},
   "source": [
    "#### 3) Passenger count:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6facca44",
   "metadata": {},
   "source": [
    "As the NYC Taxi web site reports:* \"The maximum amount of passengers allowed in a yellow taxicab by law is four (4) in a four (4) passenger taxicab or five (5) passengers in a five (5) passenger taxicab, except that an additional passenger must be accepted if such passenger is under the age of seven (7) and is held on the lap of an adult passenger seated in the rear\"*. So I remove everything below zero and higher than 5. But I must keep into acocunt also the Van service, which from/to the airport can bring up to 15 pople, even if it is an extreme case (I may consider it as an outlayer let's see later on), for the moment I am going to keep up to 15 seats. It seems good to have kept also higher number of passenger, as matter of fact for a number of seats higher than 6 the average fare amount increases. I can also observe that there is lack for number of seats between 10 and 15. It seems that for a normal trip in a yellow taxi the fare amount it is almost the same, instead for vans it positively increases with the number of passengers.\n",
    "\n",
    "To take into account this difference between Taxi and van I am goign to create an ad hoc variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c213d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|   passenger_count|\n",
      "+-------+------------------+\n",
      "|  count|          54235168|\n",
      "|   mean| 1.685401693602203|\n",
      "| stddev|1.3154630695998806|\n",
      "|    min|                 0|\n",
      "|    max|               208|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check my data:\n",
    "train.select('passenger_count').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09f5626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Train:\n",
    "train = train.filter('passenger_count > 0 AND passenger_count <=15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a5d2146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f45afbb8090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.select('passenger_count', 'fare_amount').groupby('passenger_count').agg(F.mean('fare_amount')).sort('passenger_count')\\\n",
    ".toPandas().plot.bar('passenger_count', 'avg(fare_amount)',legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af9327c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FInd whch is a taxi and whoch a van\n",
    "def taxi_or_van(df):\n",
    "    \n",
    "    df = df.withColumn('taxi_or_van', F.when( (col('passenger_count') <= 6), 'taxi')\\\n",
    "                      .otherwise('van'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bdd6ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add taxi vs van variable to df:\n",
    "\n",
    "train = taxi_or_van(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9ee7d6",
   "metadata": {},
   "source": [
    "#### 4) Fare AMount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0fb53f",
   "metadata": {},
   "source": [
    "Checking the statistics, it is clear that some values are not possible, I am going to remove negatives values and all values that are lower that 2.50 dollars (https://nymag.com/nymetro/urban/features/taxi/n_20286/). Hence, I will keep all values greather than 2.50 dollars. For what concerns the maximum it is difficult to think about a joutney in taxi for a price of 93963$. The median instead is around 325$, which is a more reasonable value. It is clear that the distribution is right skewed (mean < median) and in addition the values over the median are only 134 and looking for some of their attributes it seems that there is no real reasons to have so huge fare amount. Given that I suppose that the most of them are outlayers, therefore I am going to drop anything over the median. Furthermore, considering the high skew, it may be reasonable to drop somenthing more, too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af6423e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>54044321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>11.33294135419023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>20.86706348406584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>-300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>93963.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary        fare_amount\n",
       "0   count           54044321\n",
       "1    mean  11.33294135419023\n",
       "2  stddev  20.86706348406584\n",
       "3     min             -300.0\n",
       "4     max           93963.36"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get statistics:\n",
    "train.select('fare_amount').describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0fb86f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Values lower than 2.50$:\n",
    "train = train.filter('fare_amount > 2.50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e19c6c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.51, 375.0, 93963.36]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Quantiles:\n",
    "fair_quantiles= train.approxQuantile('fare_amount', [0.25, 0.50, 0.75], 0.25)\n",
    "fair_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "95e5ef44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs over the median: 134\n",
      "+-----------+--------------+------------------+----------+---------------+-----------+\n",
      "|fare_amount|haversine_dist|         direction|   airport|passenger_count|taxi_or_van|\n",
      "+-----------+--------------+------------------+----------+---------------+-----------+\n",
      "|      400.0|           0.0|             180.0|NO_AIRPORT|              1|       taxi|\n",
      "|      499.0|         0.012|324.26197795325294|NO_AIRPORT|              1|       taxi|\n",
      "|      475.0|         0.001|             180.0|NO_AIRPORT|              1|       taxi|\n",
      "|      450.0|         0.001| 4.396683387821781|NO_AIRPORT|              1|       taxi|\n",
      "|     377.75|        84.095| 52.57840168530231|  PICK_LGR|              1|       taxi|\n",
      "|      440.0|           0.0| 44.98473111992348|NO_AIRPORT|              1|       taxi|\n",
      "|     444.44|           0.0| 90.00000821723745|NO_AIRPORT|              1|       taxi|\n",
      "|      400.0|           0.0|               0.0|NO_AIRPORT|              1|       taxi|\n",
      "|      450.0|          0.01|309.15955313260406|NO_AIRPORT|              1|       taxi|\n",
      "|      500.0|           0.0|               0.0|NO_AIRPORT|              1|       taxi|\n",
      "+-----------+--------------+------------------+----------+---------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check some values over the median\n",
    "print('Obs over the median: {:d}'.format(train.filter('fare_amount > 375').count()))\n",
    "train.filter('fare_amount>375').select('fare_amount','haversine_dist', 'direction','airport','passenger_count','taxi_or_van').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d5cdfd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Outlayers:\n",
    "train = train.filter('fare_amount < 325')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8a1e179a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f45a7262a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "hist(ax, train.select('fare_amount'), bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285f3792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Create Csv:\n"
     ]
    }
   ],
   "source": [
    "# Save new df for the dashboard:\n",
    "print('Start Create Csv:')\n",
    "s = time()\n",
    "to_csv = train.select('fare_amount','pickup_datetime','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude', 'haversine_dist', 'direction',\n",
    "             'airport', 'long_short', 'passenger_count', 'taxi_or_van','is_week_end','part_of_day')\n",
    "to_csv = to_csv.sample(fraction=0.02, seed=123)\n",
    "to_csv.coalesce(1).write.format(\"csv\").option('header', 'true').save(PATH_BUCKET+'new_train')\n",
    "print('End creation in {:.2f} minutess'.format( (time()-s)/60 ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
